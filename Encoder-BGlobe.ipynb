{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def process_headline(headline):\n",
    "    processed = headline.replace('Â\\xa0', ' ').replace('â\\x80\\x98', \"'\")\n",
    "    if ';;;' in processed:\n",
    "        processed = processed.split(';;;')[0]\n",
    "    return processed\n",
    "\n",
    "# Assuming the CSV file is named 'data.csv' and has the correct format\n",
    "file_name = 'filteredDataBGlobe.tsv'\n",
    "\n",
    "userIDs = []\n",
    "articleHeadlines = []\n",
    "dates = []\n",
    "\n",
    "with open(file_name, mode='r', encoding='utf-8') as file:\n",
    "    tsv_reader = csv.reader(file, delimiter='\\t')\n",
    "    next(tsv_reader)  # Skip the header row if there is one\n",
    "    for row in tsv_reader:\n",
    "        userID, headline, date = row[0], row[1], row[2]\n",
    "        if headline.strip():  # Checks if headline is not empty or just whitespace\n",
    "            userIDs.append(userID)\n",
    "            processed = process_headline(headline)\n",
    "            articleHeadlines.append(processed)\n",
    "            dates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(articleHeadlines[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (user_ids[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(article_headlines[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(consumption_times[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "unique_user_ids = set()\n",
    "for user_id in userIDs:\n",
    "    if user_id not in unique_user_ids:\n",
    "        unique_user_ids.add(user_id)\n",
    "        if len(unique_user_ids) == 40000:\n",
    "            break\n",
    "\n",
    "filtered_data = [(user_id, headline, time) for user_id, headline, time in zip(userIDs, articleHeadlines, dates) if user_id in unique_user_ids]\n",
    "\n",
    "user_counts = Counter(user_id for user_id, _, _ in filtered_data)\n",
    "\n",
    "multiple_occurrence_users = {user for user, count in user_counts.items() if count > 1}\n",
    "\n",
    "combined_article_headlines = {user: [] for user in multiple_occurrence_users}\n",
    "combined_consumption_times = {user: [] for user in multiple_occurrence_users}\n",
    "\n",
    "for user_id, headline, time in filtered_data:\n",
    "    if user_id in multiple_occurrence_users:\n",
    "        if time not in combined_consumption_times[user_id]:\n",
    "            combined_consumption_times[user_id].append(time)\n",
    "            combined_article_headlines[user_id].append([headline])\n",
    "        else:\n",
    "            index = combined_consumption_times[user_id].index(time)\n",
    "            combined_article_headlines[user_id][index].append(headline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dates[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "def pad_and_stack(tensor_list):\n",
    "    max_rows = max(tensor.size(0) for tensor in tensor_list)\n",
    "    max_cols = max(tensor.size(1) for tensor in tensor_list)\n",
    "\n",
    "    padded_tensors = []\n",
    "    for tensor in tensor_list:\n",
    "        row_padding = max_rows - tensor.size(0)\n",
    "        col_padding = max_cols - tensor.size(1)\n",
    "\n",
    "        padded_tensor = pad(tensor, (0, col_padding, 0, row_padding))\n",
    "\n",
    "        padded_tensors.append(padded_tensor)\n",
    "\n",
    "    stacked_tensor = torch.stack(padded_tensors)\n",
    "\n",
    "    return stacked_tensor\n",
    "\n",
    "def pad_to_max(*tensors):\n",
    "        max_rows = max(tensor.size(0) for tensor in tensors)\n",
    "        max_cols = max(tensor.size(1) for tensor in tensors)\n",
    "        max_depth = max(tensor.size(2) for tensor in tensors)  # Add this line\n",
    "\n",
    "        # Pad each tensor and store them in a new list\n",
    "        padded_tensors = []\n",
    "        for tensor in tensors:\n",
    "            row_padding = max_rows - tensor.size(0)\n",
    "            col_padding = max_cols - tensor.size(1)\n",
    "            depth_padding = max_depth - tensor.size(2)  # Add this line\n",
    "\n",
    "            padded_tensor = F.pad(tensor, (0, depth_padding, 0, col_padding, 0, row_padding))\n",
    "\n",
    "            padded_tensors.append(padded_tensor)\n",
    "\n",
    "        return tuple(padded_tensors)\n",
    "    \n",
    "from datetime import datetime\n",
    "\n",
    "def days_between_dates(date_str, end_date_str):\n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    start_date = datetime.strptime(date_str, date_format)\n",
    "    end_date = datetime.strptime(end_date_str, date_format)\n",
    "    return (end_date - start_date).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, lstm_hidden_dim, mlp_hidden_dim, lambda_val, alpha, beta):\n",
    "        super(UserEncoder, self).__init__()\n",
    "        \n",
    "        self.sentence_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "        self.lstm = nn.LSTM(embedding_dim // 2, lstm_hidden_dim // 2, batch_first=True)\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, mlp_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden_dim, embedding_dim)\n",
    "        )\n",
    "        \n",
    "        self.lambda_val = lambda_val\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, user_ids, article_headlines, consumption_times):\n",
    "        all_embeddings = [torch.tensor(self.sentence_model.encode(headlines)) for headlines in article_headlines]\n",
    "        max_articles = max([emb.shape[0] for emb in all_embeddings])\n",
    "    \n",
    "        # Pad the embeddings to have the same size\n",
    "        padded_embeddings = []\n",
    "        for emb in all_embeddings:\n",
    "            pad_size = max_articles - emb.shape[0]\n",
    "            if pad_size > 0:\n",
    "                pad = torch.zeros(pad_size, emb.shape[1])\n",
    "                padded_emb = torch.cat([emb, pad], dim=0)\n",
    "            else:\n",
    "                padded_emb = emb\n",
    "            padded_embeddings.append(padded_emb)\n",
    "\n",
    "        \n",
    "        all_embeddings = torch.stack(padded_embeddings)\n",
    "        \n",
    "        # Compute weights for each timestamp in the sequence\n",
    "        date_format = \"%Y-%m-%d\"\n",
    "\n",
    "        \n",
    "        end_date = \"2017-12-31\"  # day after entries end \n",
    "        \n",
    "        weighted_sums = []\n",
    "        for times, embedding in zip(consumption_times, all_embeddings):\n",
    "            weighted_sum = torch.zeros_like(embedding)\n",
    "            date_range = days_between_dates(times, end_date)\n",
    "            current_date_range = date_range\n",
    "            while(current_date_range >= 0) :\n",
    "                weight = torch.exp(-self.lambda_val * torch.tensor(current_date_range))\n",
    "                weighted_sum += weight * embedding\n",
    "                current_date_range -= 1\n",
    "            weighted_sums.append(weighted_sum)        \n",
    "        #all_weights = [torch.exp(-self.lambda_val * torch.tensor(days_between_dates(times))) for times in consumption_times]\n",
    "\n",
    "        # Compute weighted sums for each timestamp\n",
    "        #weighted_sums = [weights * embeddings for weights, embeddings in zip(all_weights, all_embeddings)]\n",
    "        weighted_sums = torch.stack(weighted_sums)\n",
    "        \n",
    "        # Pass each weighted sum through the MLP to get p_consistent and p_transient\n",
    "        mlp_outputs = []\n",
    "        for weighted_sum in weighted_sums:\n",
    "            mlp_output = self.mlp(weighted_sum)\n",
    "            \n",
    "            mlp_outputs.append(mlp_output)\n",
    "\n",
    "        p_consistents = []\n",
    "        for output in mlp_outputs:\n",
    "            p_consistent = output[:, :output.shape[1] // 2]\n",
    "            p_consistents.append(p_consistent)\n",
    "\n",
    "        p_transients = [output[:, output.shape[1]//2:] for output in mlp_outputs]\n",
    "        #print (p_consistents)\n",
    "        \n",
    "        p_consistents = torch.stack(p_consistents)\n",
    "        p_transients = torch.stack(p_transients)       \n",
    "        \n",
    "        \n",
    "        lstm_out_consistent, _ = self.lstm(p_consistents)\n",
    "        lstm_out_transient, _ = self.lstm(p_transients)\n",
    "\n",
    "        updated_p_consistent = lstm_out_consistent[-1]\n",
    "        updated_p_transient = lstm_out_transient[-1]\n",
    "\n",
    "        return updated_p_consistent, updated_p_transient\n",
    "\n",
    "    def generate_positive_embeddings(self, user_ids, headlines, consumption_times):\n",
    "        random_idx = random.randint(0, len(headlines) - 1)\n",
    "        selected_headlines = headlines[random_idx]\n",
    "        selected_times = consumption_times[random_idx]\n",
    "\n",
    "        subsampled_headlines = random.sample(selected_headlines, len(selected_headlines) // 2)\n",
    "        if len(subsampled_headlines) > 1:\n",
    "            p_positive_consistent, p_positive_transient = self.forward(user_id, [subsampled_headlines], [selected_times])\n",
    "        else:\n",
    "            p_positive_consistent, p_positive_transient = self.forward(user_id, [selected_headlines], [selected_times])\n",
    "\n",
    "        return torch.cat((p_positive_consistent, p_positive_transient), dim=0)\n",
    "\n",
    "    def generate_negative_embeddings(self, user_embedding, batch_embeddings):\n",
    "        distances = torch.norm(batch_embeddings - user_embedding.unsqueeze(0), dim=1)\n",
    "        furthest_idx = distances.argmax().item()  # pick the furthest embedding\n",
    "        furthest_idx = furthest_idx % batch_embeddings.shape[0]\n",
    "        return batch_embeddings[furthest_idx]\n",
    "\n",
    "\n",
    "    def compute_loss(self, p, p_positive, p_negative):\n",
    "        p, p_positive, p_negative = pad_to_max(p, p_positive, p_negative)\n",
    "        contrastive_loss = torch.sum(F.relu(torch.norm(p[:, :p.shape[1]//2] - p_positive[:, :p_positive.shape[1]//2], dim=1)**2 - \n",
    "                                         torch.norm(p[:, :p.shape[1]//2] - p_negative[:, :p_negative.shape[1]//2], dim=1)**2 + self.alpha))\n",
    "        consistency_reg = self.beta * torch.norm(p[:, :p.shape[1]//2] - p_positive[:, :p_positive.shape[1]//2], dim=1)**2\n",
    "        total_loss = contrastive_loss + torch.sum(consistency_reg)\n",
    "        return total_loss\n",
    "\n",
    "    def training_step(self, users, combined_article_headlines, combined_consumption_times):\n",
    "\n",
    "        batch_p_consistent = []\n",
    "        batch_p_positive_consistent = []\n",
    "        batch_p_negative = []\n",
    "        \n",
    "        for user_id in users:\n",
    "            headlines_sequence = combined_article_headlines[user_id]\n",
    "            times_sequence = combined_consumption_times[user_id]\n",
    "\n",
    "            p_consistent, p_transient = self.forward(user_id, headlines_sequence, times_sequence)\n",
    "            p_pos = self.generate_positive_embeddings(user_id, headlines_sequence, times_sequence)\n",
    "            p = torch.cat((p_consistent, p_transient), dim=0)\n",
    "            \n",
    "            #pad_size = max_seq_len - p.size(0)\n",
    "            #if pad_size > 0:\n",
    "            #    p = F.pad(p, (0, 0, 0, pad_size))\n",
    "\n",
    "            batch_p_consistent.append(p)\n",
    "            \n",
    "            batch_p_positive_consistent.append(p_pos)\n",
    "\n",
    "        batch_p_consistent = pad_and_stack(batch_p_consistent)\n",
    "        batch_p_positive_consistent = pad_and_stack(batch_p_positive_consistent)\n",
    "\n",
    "        for p_consistent in batch_p_consistent:\n",
    "            p_negative = self.generate_negative_embeddings(p_consistent, batch_p_consistent)\n",
    "            batch_p_negative.append(p_negative)\n",
    "        \n",
    "        batch_p_negative = pad_and_stack(batch_p_negative)\n",
    "\n",
    "        loss = self.compute_loss(batch_p_consistent, batch_p_positive_consistent, batch_p_negative)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    }
   ],
   "source": [
    "print(len(multiple_occurrence_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "def train(model, user_ids, consumption_times, article_headlines, optimizer, num_epochs=8, batch_size=128):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "    model.train()\n",
    "    \n",
    "    user_counts = Counter(user_ids)\n",
    "    all_batch_user_ids = user_ids\n",
    "    all_batch_consumption_times = combined_consumption_times\n",
    "    all_batch_article_headlines = combined_article_headlines\n",
    "    \n",
    "    batch_user_ids = all_batch_user_ids[:3000]\n",
    "    batch_consumption_times = all_batch_consumption_times\n",
    "    batch_article_headlines = all_batch_article_headlines\n",
    "    \n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for i in range(0, len(batch_user_ids), batch_size):\n",
    "            mini_batch_user_ids = batch_user_ids[i:i+batch_size]\n",
    "            mini_batch_consumption_times = batch_consumption_times\n",
    "            mini_batch_article_headlines = batch_article_headlines\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = model.training_step(mini_batch_user_ids, mini_batch_article_headlines, mini_batch_consumption_times)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        scheduler.step()\n",
    "        # Calculate and print the average loss per batch\n",
    "        avg_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}, Learning Rate: {scheduler.get_last_lr()[0]}\")\n",
    "\n",
    "# Assuming the model and data are defined\n",
    "embedding_dim = 768\n",
    "lstm_hidden_dim = 512\n",
    "mlp_hidden_dim = 256\n",
    "lambda_val = 0.5\n",
    "alpha = 0.5\n",
    "beta = 0.5\n",
    "\n",
    "model = UserEncoder(embedding_dim, lstm_hidden_dim, mlp_hidden_dim, lambda_val, alpha, beta)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Loss: 17053.64813232422, Learning Rate: 0.05\n",
      "Epoch 2/8, Loss: 16808.1440226237, Learning Rate: 0.045000000000000005\n",
      "Epoch 3/8, Loss: 16402.026306152344, Learning Rate: 0.045000000000000005\n",
      "Epoch 4/8, Loss: 16227.155456542969, Learning Rate: 0.04050000000000001\n",
      "Epoch 5/8, Loss: 16335.091878255209, Learning Rate: 0.04050000000000001\n",
      "Epoch 6/8, Loss: 15925.215087890625, Learning Rate: 0.03645000000000001\n",
      "Epoch 7/8, Loss: 16354.216369628906, Learning Rate: 0.03645000000000001\n",
      "Epoch 8/8, Loss: 16273.047892252604, Learning Rate: 0.03280500000000001\n"
     ]
    }
   ],
   "source": [
    "mu_users = list(multiple_occurrence_users)\n",
    "train(model, mu_users, combined_article_headlines, combined_article_headlines, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'encoderFinal2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_sequence = []\n",
    "times_sequence = []\n",
    "user_ids_list = ['U102704']\n",
    "user_ids2_list = ['U207812']\n",
    "headlines_sequence_2 = [['Luxury store sets minimum spend for Santa encounters', 'University athlete meets tragic fate in practice session', 'Dairy giant Dean Foods goes bankrupt', 'Lawsuit against firearm maker gets green light from Supreme Court', 'Child succumbs to gunshot wound', 'College freshman dies after incident at fraternity house', 'Evidence of Turkish Forces targeting civilians captured by U.S. Drones', 'Seahawks triumph in nail-biting overtime against 49ers'], ['Parent brings baby to drug transaction, child gets injured', 'Prominent Solar Panel Manufacturer Shuts Down Production', 'For Sale: Deserted Missile Complex in Arizona listed at $400k', 'Firefighter loses life in line of duty in Massachusetts', 'Valiant Officer Pulls Driver From Flaming Wreckage', 'McLaren Reveals the Elva: A Windshield-less Hypercar Priced at $1.7 Million', 'Universities in Hong Kong under siege as police crackdown intensifies']]\n",
    "\n",
    "\n",
    "headlines_sequence = combined_article_headlines['U102704']\n",
    "print (headlines_sequence)\n",
    "print (headlines_sequence_2)\n",
    "times_sequence = combined_consumption_times[user_ids_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient computation during inference for efficiency\n",
    "    predictions = model(user_ids_list, headlines_sequence, times_sequence)\n",
    "    predictions2 = model(user_ids2_list, headlines_sequence_2, times_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (multiple_occurrence_users[3501])\n",
    "print (predictions[0][7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = predictions2 - predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_tuple = tuple(tensor2 - tensor1 for tensor1, tensor2 in zip(predictions2, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(difference_tuple[1][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_consumption_times = [combined_consumption_times[user_id] for user_id in predict_user_ids]\n",
    "predict_article_headlines = [combined_article_headlines[user_id] for user_id in predict_user_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_consumption_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "are_identical = all(torch.equal(tensor1, tensor2) for tensor1, tensor2 in zip(predictions, predictions2))\n",
    "\n",
    "print(\"Tuples are identical:\", are_identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_difference = sum(torch.abs(tensor2 - tensor1).sum() for tensor1, tensor2 in zip(predictions2, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_list = ['U102704']\n",
    "user_ids2_list = ['U207812']\n",
    "headlines_sequence_2 = [['Luxury store sets minimum spend for Santa encounters', 'University athlete meets tragic fate in practice session', 'Dairy giant Dean Foods goes bankrupt', 'Lawsuit against firearm maker gets green light from Supreme Court', 'Child succumbs to gunshot wound', 'College freshman dies after incident at fraternity house', 'Evidence of Turkish Forces targeting civilians captured by U.S. Drones', 'Seahawks triumph in nail-biting overtime against 49ers'], ['Parent brings baby to drug transaction, child gets injured', 'Prominent Solar Panel Manufacturer Shuts Down Production', 'For Sale: Deserted Missile Complex in Arizona listed at $400k', 'Firefighter loses life in line of duty in Massachusetts', 'Valiant Officer Pulls Driver From Flaming Wreckage', 'McLaren Reveals the Elva: A Windshield-less Hypercar Priced at $1.7 Million', 'Universities in Hong Kong under siege as police crackdown intensifies']]\n",
    "\n",
    "\n",
    "headlines_sequence = combined_article_headlines['U102704']\n",
    "#print (headlines_sequence)\n",
    "#print (headlines_sequence_2)\n",
    "times_sequence = combined_consumption_times[user_ids_list[0]]\n",
    "\n",
    "with torch.no_grad():  \n",
    "    predictions = model(user_ids_list, headlines_sequence, times_sequence)\n",
    "    predictions2 = model(user_ids2_list, headlines_sequence, times_sequence)\n",
    "\n",
    "    are_identical = all(torch.equal(tensor1, tensor2) for tensor1, tensor2 in zip(predictions, predictions2))\n",
    "\n",
    "print(\"Tuples are identical:\", are_identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_sequence_3 = [['Local bakery introduces new line of vegan pastries', 'Researchers discover new species of deep-sea creatures', 'City plans to open new public library next month', 'Scientists announce breakthrough in renewable energy technology', 'Young pianist wins international music competition', 'University unveils plans for environmentally-friendly campus renovations', 'Rare bird species spotted in local wildlife reserve', '5 highlights from the latest tech expo'], ['Gardener discovers ancient artifact in backyard', 'New planet discovered in our solar system', 'Local artist transforms abandoned building into public art space', 'Veterinarian volunteers to help injured wildlife in rainforest', 'Firefighter adopts dog he rescued from burning building', 'The latest electric car model breaks records for speed and efficiency', 'International Food Festival attracts visitors from around the globe']]\n",
    "\n",
    "with torch.no_grad():  \n",
    "    predictions = model(user_ids_list, headlines_sequence, times_sequence)\n",
    "    predictions2 = model(user_ids2_list, headlines_sequence_3, times_sequence)\n",
    "\n",
    "    are_identical = all(torch.equal(tensor1, tensor2) for tensor1, tensor2 in zip(predictions, predictions2))\n",
    "\n",
    "print(\"Tuples are identical:\", are_identical)\n",
    "\n",
    "total_difference = sum(torch.abs(tensor2 - tensor1).sum() for tensor1, tensor2 in zip(predictions2, predictions))\n",
    "\n",
    "print(total_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_sequence_2 = [10,11]\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(user_ids_list, headlines_sequence, times_sequence)\n",
    "    predictions2 = model(user_ids2_list, headlines_sequence, times_sequence)\n",
    "\n",
    "    are_identical = all(torch.equal(tensor1, tensor2) for tensor1, tensor2 in zip(predictions, predictions2))\n",
    "    \n",
    "total_difference = sum(torch.abs(tensor2 - tensor1).sum() for tensor1, tensor2 in zip(predictions2, predictions))\n",
    "\n",
    "print(total_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperenv",
   "language": "python",
   "name": "whisperenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
