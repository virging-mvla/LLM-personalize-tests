{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial user_data shape: (2232748, 5)\n",
      "Initial article_data shape: (101527, 8)\n",
      "Number of users with at least one article with -1 suffix: 2232748\n",
      "User data after processing columns shape: (2232748, 3)\n",
      "User data after filtering shape: (618930, 3)\n",
      "Merged data shape: (1769838, 5)\n",
      "Grouped data shape: (512971, 3)\n",
      "User data after filtering users appearing multiple times shape: (618930, 3)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(user_tsv_path, article_tsv_path):\n",
    "    # Read the TSVs\n",
    "    user_data = pd.read_csv(user_tsv_path, sep='\\t', header=None)\n",
    "    article_data = pd.read_csv(article_tsv_path, sep='\\t', header=None)\n",
    "    \n",
    "    print(\"Initial user_data shape:\", user_data.shape)\n",
    "    print(\"Initial article_data shape:\", article_data.shape)\n",
    "    \n",
    "    user_ids_col = user_data[1]\n",
    "    consumption_times_col = user_data[2].apply(lambda x: int(x.split(' ')[0].split('/')[1]))  # Extract day of the month\n",
    "    article_ids_col = user_data[4]\n",
    "    \n",
    "    article_id_col = article_data[0]\n",
    "    headlines_col = article_data[3]\n",
    "    \n",
    "    article_ids_col = article_ids_col.apply(lambda x: [i[:-2] for i in str(x).split(' ') if i.endswith('-1')])\n",
    "        \n",
    "    users_with_minus_one = article_ids_col[article_ids_col.apply(len) > 0]\n",
    "    print(\"Number of users with at least one article with -1 suffix:\", len(users_with_minus_one))\n",
    "    \n",
    "    user_data_processed = pd.DataFrame({\n",
    "        'User_ID': user_ids_col,\n",
    "        'Date_of_Consumption': consumption_times_col,\n",
    "        'Article_IDs': article_ids_col\n",
    "    })\n",
    "    \n",
    "    print(\"User data after processing columns shape:\", user_data_processed.shape)\n",
    "    \n",
    "    # Filter out users with less than two articles\n",
    "    user_data_processed = user_data_processed[user_data_processed['Article_IDs'].apply(len) >= 2]\n",
    "    \n",
    "    print(\"User data after filtering shape:\", user_data_processed.shape)\n",
    "    \n",
    "    # Create a dataframe for articles\n",
    "    article_data_processed = pd.DataFrame({\n",
    "        'Article_ID': article_id_col,\n",
    "        'Headline': headlines_col\n",
    "    })\n",
    "    \n",
    "    merged_data = user_data_processed.explode('Article_IDs').merge(article_data_processed, left_on='Article_IDs', right_on='Article_ID')\n",
    "    \n",
    "    print(\"Merged data shape:\", merged_data.shape)\n",
    "    \n",
    "    grouped_data = merged_data.groupby(['User_ID', 'Date_of_Consumption'])['Headline'].apply(list).reset_index()\n",
    "    \n",
    "    print(\"Grouped data shape:\", grouped_data.shape)\n",
    "    \n",
    "    user_ids = grouped_data['User_ID'].tolist()\n",
    "    consumption_days = grouped_data['Date_of_Consumption'].tolist()\n",
    "    article_headlines = grouped_data['Headline'].tolist()\n",
    "    \n",
    "    \n",
    "    #user_counts = user_data_processed['User_ID'].value_counts()\n",
    "    #valid_users = user_counts[user_counts > 1].index.tolist()\n",
    "    #user_data_processed = user_data_processed[user_data_processed['User_ID'].isin(valid_users)]\n",
    "    \n",
    "    print(\"User data after filtering users appearing multiple times shape:\", user_data_processed.shape)\n",
    "    \n",
    "    # Filter out corresponding article headlines and consumption times\n",
    "    #valid_indices = user_data_processed.index.tolist()\n",
    "    #user_ids = [user_ids[i] for i in valid_indices]\n",
    "    #consumption_days = [consumption_days[i] for i in valid_indices]\n",
    "    #article_headlines = [article_headlines[i] for i in valid_indices]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return user_ids, consumption_days, article_headlines\n",
    "    \n",
    "\n",
    "user_tsv_path = 'originalData/behaviors.tsv'\n",
    "article_tsv_path = 'originalData/news.tsv'\n",
    "user_ids, consumption_times, article_headlines = preprocess_data(user_tsv_path, article_tsv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U101166\n"
     ]
    }
   ],
   "source": [
    "print (user_ids[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Stephen Curry calls out Michael Jordan for being a 'hater'\", 'U.S. Drones Appear to Show Turkish- Backed Forces Targeting Civilians']\n"
     ]
    }
   ],
   "source": [
    "print(article_headlines[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(consumption_times[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gvirgink/anaconda3/envs/whisperenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_user_ids = []\n",
    "for user_id in user_ids:\n",
    "    if user_id not in unique_user_ids:\n",
    "        unique_user_ids.append(user_id)\n",
    "    if len(unique_user_ids) == 10000:\n",
    "        break\n",
    "\n",
    "user_ids = [user_id for user_id in user_ids if user_id in unique_user_ids]\n",
    "article_headlines = [article_headlines[i] for i, user_id in enumerate(user_ids) if user_id in unique_user_ids]\n",
    "consumption_times = [consumption_times[i] for i, user_id in enumerate(user_ids) if user_id in unique_user_ids]\n",
    "\n",
    "from collections import Counter\n",
    "user_counts = Counter(user_ids)\n",
    "multiple_occurrence_users = [user for user, count in user_counts.items() if count > 1]\n",
    "\n",
    "combined_article_headlines = {user: [] for user in multiple_occurrence_users}\n",
    "combined_consumption_times = {user: [] for user in multiple_occurrence_users}\n",
    "\n",
    "for user_id, headlines, times in zip(user_ids, article_headlines, consumption_times):\n",
    "    if user_id in multiple_occurrence_users:\n",
    "        combined_article_headlines[user_id].append(headlines)\n",
    "        combined_consumption_times[user_id].append(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "def pad_and_stack(tensor_list):\n",
    "    max_rows = max(tensor.size(0) for tensor in tensor_list)\n",
    "    max_cols = max(tensor.size(1) for tensor in tensor_list)\n",
    "\n",
    "    padded_tensors = []\n",
    "    for tensor in tensor_list:\n",
    "        row_padding = max_rows - tensor.size(0)\n",
    "        col_padding = max_cols - tensor.size(1)\n",
    "\n",
    "        padded_tensor = pad(tensor, (0, col_padding, 0, row_padding))\n",
    "\n",
    "        padded_tensors.append(padded_tensor)\n",
    "\n",
    "    stacked_tensor = torch.stack(padded_tensors)\n",
    "\n",
    "    return stacked_tensor\n",
    "\n",
    "def pad_to_max(*tensors):\n",
    "        max_rows = max(tensor.size(0) for tensor in tensors)\n",
    "        max_cols = max(tensor.size(1) for tensor in tensors)\n",
    "        max_depth = max(tensor.size(2) for tensor in tensors)  # Add this line\n",
    "\n",
    "        # Pad each tensor and store them in a new list\n",
    "        padded_tensors = []\n",
    "        for tensor in tensors:\n",
    "            row_padding = max_rows - tensor.size(0)\n",
    "            col_padding = max_cols - tensor.size(1)\n",
    "            depth_padding = max_depth - tensor.size(2)  # Add this line\n",
    "\n",
    "            padded_tensor = F.pad(tensor, (0, depth_padding, 0, col_padding, 0, row_padding))\n",
    "\n",
    "            padded_tensors.append(padded_tensor)\n",
    "\n",
    "        return tuple(padded_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, lstm_hidden_dim, mlp_hidden_dim, lambda_val, alpha, beta):\n",
    "        super(UserEncoder, self).__init__()\n",
    "        \n",
    "        self.sentence_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "        self.lstm = nn.LSTM(embedding_dim // 2, lstm_hidden_dim // 2, batch_first=True)\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, mlp_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden_dim, embedding_dim)\n",
    "        )\n",
    "        \n",
    "        self.lambda_val = lambda_val\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, user_ids, article_headlines, consumption_times):\n",
    "        all_embeddings = [torch.tensor(self.sentence_model.encode(headlines)) for headlines in article_headlines]\n",
    "        max_articles = max([emb.shape[0] for emb in all_embeddings])\n",
    "    \n",
    "        # Pad the embeddings to have the same size\n",
    "        padded_embeddings = []\n",
    "        for emb in all_embeddings:\n",
    "            pad_size = max_articles - emb.shape[0]\n",
    "            if pad_size > 0:\n",
    "                pad = torch.zeros(pad_size, emb.shape[1])\n",
    "                padded_emb = torch.cat([emb, pad], dim=0)\n",
    "            else:\n",
    "                padded_emb = emb\n",
    "            padded_embeddings.append(padded_emb)\n",
    "\n",
    "        # Stack the padded embeddings\n",
    "        \n",
    "        all_embeddings = torch.stack(padded_embeddings)\n",
    "\n",
    "        # Compute weights for each timestamp in the sequence\n",
    "        current_time = torch.tensor(15)  # day after entries end \n",
    "        all_weights = [torch.exp(-self.lambda_val * (current_time - times)) for times in consumption_times]\n",
    "\n",
    "        # Compute weighted sums for each timestamp\n",
    "        weighted_sums = [weights * embeddings for weights, embeddings in zip(all_weights, all_embeddings)]\n",
    "        weighted_sums = torch.stack(weighted_sums)\n",
    "        \n",
    "        # Pass each weighted sum through the MLP to get p_consistent and p_transient\n",
    "        mlp_outputs = [self.mlp(weighted_sum) for weighted_sum in weighted_sums]\n",
    "        p_consistents = [output[:, :output.shape[1]//2] for output in mlp_outputs]\n",
    "        p_transients = [output[:, output.shape[1]//2:] for output in mlp_outputs]\n",
    "        #print (p_consistents)\n",
    "        \n",
    "        p_consistents = torch.stack(p_consistents)\n",
    "        p_transients = torch.stack(p_transients)       \n",
    "        \n",
    "        \n",
    "        lstm_out_consistent, _ = self.lstm(p_consistents)\n",
    "        lstm_out_transient, _ = self.lstm(p_transients)\n",
    "\n",
    "        updated_p_consistent = lstm_out_consistent[-1]\n",
    "        updated_p_transient = lstm_out_transient[-1]\n",
    "\n",
    "        return updated_p_consistent, updated_p_transient\n",
    "\n",
    "    def generate_positive_embeddings(self, user_ids, headlines, consumption_times):\n",
    "        random_idx = random.randint(0, len(headlines) - 1)\n",
    "        selected_headlines = headlines[random_idx]\n",
    "        selected_times = consumption_times[random_idx]\n",
    "\n",
    "        # Randomly subsample half of the articles for the positive embeddings\n",
    "        subsampled_headlines = random.sample(selected_headlines, len(selected_headlines) // 2)\n",
    "        if len(subsampled_headlines) > 1:\n",
    "            p_positive_consistent, p_positive_transient = self.forward(user_id, [subsampled_headlines], [selected_times])\n",
    "        else:\n",
    "            p_positive_consistent, p_positive_transient = self.forward(user_id, [selected_headlines], [selected_times])\n",
    "\n",
    "        return torch.cat((p_positive_consistent, p_positive_transient), dim=0)\n",
    "\n",
    "    def generate_negative_embeddings(self, user_embedding, batch_embeddings):\n",
    "        distances = torch.norm(batch_embeddings - user_embedding.unsqueeze(0), dim=1)\n",
    "        furthest_idx = distances.argmax().item()  # pick the furthest embedding\n",
    "        furthest_idx = furthest_idx % batch_embeddings.shape[0]\n",
    "        return batch_embeddings[furthest_idx]\n",
    "\n",
    "    #def compute_loss(self, p, p_positive, p_negative):\n",
    "        #contrastive_loss = torch.sum(F.relu(torch.norm(p - p_positive, dim=1)**2 - torch.norm(p - p_negative, dim=1)**2 + self.alpha))\n",
    "        #consistency_reg = self.beta * torch.norm(p[:, :p.shape[1]//2] - p_positive[:, :p_positive.shape[1]//2], dim=1)**2\n",
    "        #total_loss = contrastive_loss + torch.sum(consistency_reg)\n",
    "    #    return total_loss\n",
    "    \n",
    "    def compute_loss(self, p, p_positive, p_negative):\n",
    "        p, p_positive, p_negative = pad_to_max(p, p_positive, p_negative)\n",
    "        contrastive_loss = torch.sum(F.relu(torch.norm(p[:, :p.shape[1]//2] - p_positive[:, :p_positive.shape[1]//2], dim=1)**2 - \n",
    "                                         torch.norm(p[:, :p.shape[1]//2] - p_negative[:, :p_negative.shape[1]//2], dim=1)**2 + self.alpha))\n",
    "        consistency_reg = self.beta * torch.norm(p[:, :p.shape[1]//2] - p_positive[:, :p_positive.shape[1]//2], dim=1)**2\n",
    "        total_loss = contrastive_loss + torch.sum(consistency_reg)\n",
    "        return total_loss\n",
    "\n",
    "    def training_step(self, multiple_occurrence_users, combined_article_headlines, combined_consumption_times):\n",
    "\n",
    "        batch_p_consistent = []\n",
    "        batch_p_positive_consistent = []\n",
    "        batch_p_negative = []\n",
    "        \n",
    "        #max_seq_len = max([len(p) for user_id in multiple_occurrence_users for p in combined_article_headlines[user_id]])\n",
    "\n",
    "        for user_id in multiple_occurrence_users:\n",
    "            headlines_sequence = combined_article_headlines[user_id]\n",
    "            times_sequence = combined_consumption_times[user_id]\n",
    "\n",
    "            p_consistent, p_transient = self.forward(user_id, headlines_sequence, times_sequence)\n",
    "            p_pos = self.generate_positive_embeddings(user_id, headlines_sequence, times_sequence)\n",
    "            p = torch.cat((p_consistent, p_transient), dim=0)\n",
    "            \n",
    "            #pad_size = max_seq_len - p.size(0)\n",
    "            #if pad_size > 0:\n",
    "            #    p = F.pad(p, (0, 0, 0, pad_size))\n",
    "\n",
    "            batch_p_consistent.append(p)\n",
    "            \n",
    "            batch_p_positive_consistent.append(p_pos)\n",
    "\n",
    "        batch_p_consistent = pad_and_stack(batch_p_consistent)\n",
    "        batch_p_positive_consistent = pad_and_stack(batch_p_positive_consistent)\n",
    "\n",
    "        for p_consistent in batch_p_consistent:\n",
    "            p_negative = self.generate_negative_embeddings(p_consistent, batch_p_consistent)\n",
    "            batch_p_negative.append(p_negative)\n",
    "        \n",
    "        batch_p_negative = pad_and_stack(batch_p_negative)\n",
    "\n",
    "        loss = self.compute_loss(batch_p_consistent, batch_p_positive_consistent, batch_p_negative)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "def train(model, user_ids, consumption_times, article_headlines, optimizer, num_epochs=8, batch_size=128):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "    model.train()\n",
    "    \n",
    "    user_counts = Counter(user_ids)\n",
    "    all_batch_user_ids = multiple_occurrence_users\n",
    "    all_batch_consumption_times = combined_consumption_times\n",
    "    all_batch_article_headlines = combined_article_headlines\n",
    "    \n",
    "    batch_user_ids = all_batch_user_ids[:3000]\n",
    "    batch_consumption_times = all_batch_consumption_times\n",
    "    batch_article_headlines = all_batch_article_headlines\n",
    "    \n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for i in range(0, len(batch_user_ids), batch_size):\n",
    "            mini_batch_user_ids = batch_user_ids[i:i+batch_size]\n",
    "            mini_batch_consumption_times = batch_consumption_times\n",
    "            mini_batch_article_headlines = batch_article_headlines\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = model.training_step(mini_batch_user_ids, mini_batch_article_headlines, mini_batch_consumption_times)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        scheduler.step()\n",
    "        # Calculate and print the average loss per batch\n",
    "        avg_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}, Learning Rate: {scheduler.get_last_lr()[0]}\")\n",
    "\n",
    "embedding_dim = 768\n",
    "lstm_hidden_dim = 512\n",
    "mlp_hidden_dim = 256\n",
    "lambda_val = 0.5\n",
    "alpha = 0.5\n",
    "beta = 0.5\n",
    "\n",
    "model = UserEncoder(embedding_dim, lstm_hidden_dim, mlp_hidden_dim, lambda_val, alpha, beta)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Loss: 21881.178080240887, Learning Rate: 0.05\n",
      "Epoch 2/8, Loss: 16422.940348307293, Learning Rate: 0.045000000000000005\n",
      "Epoch 3/8, Loss: 16315.850016276041, Learning Rate: 0.045000000000000005\n",
      "Epoch 4/8, Loss: 16237.884338378906, Learning Rate: 0.04050000000000001\n",
      "Epoch 5/8, Loss: 16235.413635253906, Learning Rate: 0.04050000000000001\n",
      "Epoch 6/8, Loss: 16236.9609375, Learning Rate: 0.03645000000000001\n",
      "Epoch 7/8, Loss: 16236.731018066406, Learning Rate: 0.03645000000000001\n",
      "Epoch 8/8, Loss: 16239.646219889322, Learning Rate: 0.03280500000000001\n"
     ]
    }
   ],
   "source": [
    "train(model, user_ids, consumption_times, article_headlines, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'encoderFinal2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Harrods accused of ruining the spirit of Christmas after limiting Santa visits to customers who spend over $2,500', 'College gymnast dies following training accident in Connecticut', 'Dean Foods files for bankruptcy', 'Supreme Court refuses to block lawsuit against gun manufacturer brought by Sandy Hook families', '11-year-old boy dies after being shot in chest', 'San Diego State University freshman hurt in fraternity incident dies', 'U.S. Drones Appear to Show Turkish- Backed Forces Targeting Civilians', \"4 takeaways from the Seahawks' wild, overtime win over the 49ers\"], [\"Dad took 11-month-old to drug deal as 'human shield'. The baby was shot.\", \"One of America's biggest solar panel makers quits manufacturing\", 'A decommissioned nuclear missile complex in Arizona that was abandoned for decades is now on sale for $400,000', 'Massachusetts fire lieutenant dies battling house fire', 'Hero Police Officer Saves Driver From Fiery Crash', 'The McLaren Elva Is a $1.7 Million Topless, Windshield-less Hypercar', 'Hong Kong Colleges Become Besieged Citadels as Police Close In']]\n",
      "[['Luxury store sets minimum spend for Santa encounters', 'University athlete meets tragic fate in practice session', 'Dairy giant Dean Foods goes bankrupt', 'Lawsuit against firearm maker gets green light from Supreme Court', 'Child succumbs to gunshot wound', 'College freshman dies after incident at fraternity house', 'Evidence of Turkish Forces targeting civilians captured by U.S. Drones', 'Seahawks triumph in nail-biting overtime against 49ers'], ['Parent brings baby to drug transaction, child gets injured', 'Prominent Solar Panel Manufacturer Shuts Down Production', 'For Sale: Deserted Missile Complex in Arizona listed at $400k', 'Firefighter loses life in line of duty in Massachusetts', 'Valiant Officer Pulls Driver From Flaming Wreckage', 'McLaren Reveals the Elva: A Windshield-less Hypercar Priced at $1.7 Million', 'Universities in Hong Kong under siege as police crackdown intensifies']]\n"
     ]
    }
   ],
   "source": [
    "headlines_sequence = []\n",
    "times_sequence = []\n",
    "user_ids_list = ['U102704']\n",
    "user_ids2_list = ['U207812']\n",
    "headlines_sequence_2 = [['Luxury store sets minimum spend for Santa encounters', 'University athlete meets tragic fate in practice session', 'Dairy giant Dean Foods goes bankrupt', 'Lawsuit against firearm maker gets green light from Supreme Court', 'Child succumbs to gunshot wound', 'College freshman dies after incident at fraternity house', 'Evidence of Turkish Forces targeting civilians captured by U.S. Drones', 'Seahawks triumph in nail-biting overtime against 49ers'], ['Parent brings baby to drug transaction, child gets injured', 'Prominent Solar Panel Manufacturer Shuts Down Production', 'For Sale: Deserted Missile Complex in Arizona listed at $400k', 'Firefighter loses life in line of duty in Massachusetts', 'Valiant Officer Pulls Driver From Flaming Wreckage', 'McLaren Reveals the Elva: A Windshield-less Hypercar Priced at $1.7 Million', 'Universities in Hong Kong under siege as police crackdown intensifies']]\n",
    "\n",
    "\n",
    "headlines_sequence = combined_article_headlines['U102704']\n",
    "print (headlines_sequence)\n",
    "print (headlines_sequence_2)\n",
    "times_sequence = combined_consumption_times[user_ids_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient computation during inference for efficiency\n",
    "    predictions = model(user_ids_list, headlines_sequence, times_sequence)\n",
    "    predictions2 = model(user_ids2_list, headlines_sequence_2, times_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (multiple_occurrence_users[3501])\n",
    "print (predictions[0][7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = predictions2 - predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_tuple = tuple(tensor2 - tensor1 for tensor1, tensor2 in zip(predictions2, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(difference_tuple[1][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_consumption_times = [combined_consumption_times[user_id] for user_id in predict_user_ids]\n",
    "predict_article_headlines = [combined_article_headlines[user_id] for user_id in predict_user_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_consumption_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuples are identical: False\n"
     ]
    }
   ],
   "source": [
    "are_identical = all(torch.equal(tensor1, tensor2) for tensor1, tensor2 in zip(predictions, predictions2))\n",
    "\n",
    "print(\"Tuples are identical:\", are_identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_difference = sum(torch.abs(tensor2 - tensor1).sum() for tensor1, tensor2 in zip(predictions2, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4125e-21)\n"
     ]
    }
   ],
   "source": [
    "print(total_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuples are identical: True\n"
     ]
    }
   ],
   "source": [
    "user_ids_list = ['U102704']\n",
    "user_ids2_list = ['U207812']\n",
    "headlines_sequence_2 = [['Luxury store sets minimum spend for Santa encounters', 'University athlete meets tragic fate in practice session', 'Dairy giant Dean Foods goes bankrupt', 'Lawsuit against firearm maker gets green light from Supreme Court', 'Child succumbs to gunshot wound', 'College freshman dies after incident at fraternity house', 'Evidence of Turkish Forces targeting civilians captured by U.S. Drones', 'Seahawks triumph in nail-biting overtime against 49ers'], ['Parent brings baby to drug transaction, child gets injured', 'Prominent Solar Panel Manufacturer Shuts Down Production', 'For Sale: Deserted Missile Complex in Arizona listed at $400k', 'Firefighter loses life in line of duty in Massachusetts', 'Valiant Officer Pulls Driver From Flaming Wreckage', 'McLaren Reveals the Elva: A Windshield-less Hypercar Priced at $1.7 Million', 'Universities in Hong Kong under siege as police crackdown intensifies']]\n",
    "\n",
    "\n",
    "headlines_sequence = combined_article_headlines['U102704']\n",
    "#print (headlines_sequence)\n",
    "#print (headlines_sequence_2)\n",
    "times_sequence = combined_consumption_times[user_ids_list[0]]\n",
    "\n",
    "with torch.no_grad():  \n",
    "    predictions = model(user_ids_list, headlines_sequence, times_sequence)\n",
    "    predictions2 = model(user_ids2_list, headlines_sequence, times_sequence)\n",
    "\n",
    "    are_identical = all(torch.equal(tensor1, tensor2) for tensor1, tensor2 in zip(predictions, predictions2))\n",
    "\n",
    "print(\"Tuples are identical:\", are_identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuples are identical: False\n",
      "tensor(1.0065e-08)\n"
     ]
    }
   ],
   "source": [
    "headlines_sequence_3 = [['Local bakery introduces new line of vegan pastries', 'Researchers discover new species of deep-sea creatures', 'City plans to open new public library next month', 'Scientists announce breakthrough in renewable energy technology', 'Young pianist wins international music competition', 'University unveils plans for environmentally-friendly campus renovations', 'Rare bird species spotted in local wildlife reserve', '5 highlights from the latest tech expo'], ['Gardener discovers ancient artifact in backyard', 'New planet discovered in our solar system', 'Local artist transforms abandoned building into public art space', 'Veterinarian volunteers to help injured wildlife in rainforest', 'Firefighter adopts dog he rescued from burning building', 'The latest electric car model breaks records for speed and efficiency', 'International Food Festival attracts visitors from around the globe']]\n",
    "\n",
    "with torch.no_grad():  \n",
    "    predictions = model(user_ids_list, headlines_sequence, times_sequence)\n",
    "    predictions2 = model(user_ids2_list, headlines_sequence_3, times_sequence)\n",
    "\n",
    "    are_identical = all(torch.equal(tensor1, tensor2) for tensor1, tensor2 in zip(predictions, predictions2))\n",
    "\n",
    "print(\"Tuples are identical:\", are_identical)\n",
    "\n",
    "total_difference = sum(torch.abs(tensor2 - tensor1).sum() for tensor1, tensor2 in zip(predictions2, predictions))\n",
    "\n",
    "print(total_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "times_sequence_2 = [10,11]\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(user_ids_list, headlines_sequence, times_sequence)\n",
    "    predictions2 = model(user_ids2_list, headlines_sequence, times_sequence)\n",
    "\n",
    "    are_identical = all(torch.equal(tensor1, tensor2) for tensor1, tensor2 in zip(predictions, predictions2))\n",
    "    \n",
    "total_difference = sum(torch.abs(tensor2 - tensor1).sum() for tensor1, tensor2 in zip(predictions2, predictions))\n",
    "\n",
    "print(total_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperenv",
   "language": "python",
   "name": "whisperenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
